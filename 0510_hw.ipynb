{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%env KERAS_BACKED=tensorflow",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "env: KERAS_BACKED=tensorflow\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.datasets import imdb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n#這裡限制只選「最常用」1 萬字",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n17465344/17464789 [==============================] - 3s 0us/step\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('訓練總筆數:', len(x_train))\nprint('測試總筆數:', len(x_test))",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "訓練總筆數: 25000\n測試總筆數: 25000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 輸入資料部份\n我們來看一下輸入部份長什麼樣子?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train[24999]\n#注意這其實是一個 list 而不是 array, 原因是每筆資料 (每段影評) 長度自然是不一樣的! 我們檢查一下前 10 筆的長度就可以知道。 (from 老師的git hub)\n#數字是字常不常用的頻率",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "[1,\n 17,\n 6,\n 194,\n 337,\n 7,\n 4,\n 204,\n 22,\n 45,\n 254,\n 8,\n 106,\n 14,\n 123,\n 4,\n 2,\n 270,\n 2,\n 5,\n 2,\n 2,\n 732,\n 2098,\n 101,\n 405,\n 39,\n 14,\n 1034,\n 4,\n 1310,\n 9,\n 115,\n 50,\n 305,\n 12,\n 47,\n 4,\n 168,\n 5,\n 235,\n 7,\n 38,\n 111,\n 699,\n 102,\n 7,\n 4,\n 4039,\n 9245,\n 9,\n 24,\n 6,\n 78,\n 1099,\n 17,\n 2345,\n 2,\n 21,\n 27,\n 9685,\n 6139,\n 5,\n 2,\n 1603,\n 92,\n 1183,\n 4,\n 1310,\n 7,\n 4,\n 204,\n 42,\n 97,\n 90,\n 35,\n 221,\n 109,\n 29,\n 127,\n 27,\n 118,\n 8,\n 97,\n 12,\n 157,\n 21,\n 6789,\n 2,\n 9,\n 6,\n 66,\n 78,\n 1099,\n 4,\n 631,\n 1191,\n 5,\n 2642,\n 272,\n 191,\n 1070,\n 6,\n 7585,\n 8,\n 2197,\n 2,\n 2,\n 544,\n 5,\n 383,\n 1271,\n 848,\n 1468,\n 2,\n 497,\n 2,\n 8,\n 1597,\n 8778,\n 2,\n 21,\n 60,\n 27,\n 239,\n 9,\n 43,\n 8368,\n 209,\n 405,\n 10,\n 10,\n 12,\n 764,\n 40,\n 4,\n 248,\n 20,\n 12,\n 16,\n 5,\n 174,\n 1791,\n 72,\n 7,\n 51,\n 6,\n 1739,\n 22,\n 4,\n 204,\n 131,\n 9]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(len(x_train[24999]),len(x_train[9982]))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "153 156\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing import sequence",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 送入神經網路的輸入處理\n● 設輸入文字長度的上限 \n● 把每段文字都弄成一樣長, 太短的後面補上 0"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train = sequence.pad_sequences(x_train, maxlen=150)\nx_test = sequence.pad_sequences(x_test, maxlen=150)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train.shape",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "(25000, 150)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 打造 RNN¶ \n### 上課版本\n選用 LSTM\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "N = 3 # 文字要壓到 N 維\nK = 4 # LSTM 有 K 個神經元",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Embedding\nfrom keras.layers import LSTM",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(Embedding(10000, N))\n\n#LSTM 層, 我們做 K 個 LSTM Cells。\nmodel.add(LSTM(K))\n\n#單純透過 sigmoid 輸出\nmodel.add(Dense(1, activation='sigmoid'))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#組裝\nmodel.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\nmodel.summary()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, None, 3)           30000     \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 4)                 128       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 5         \n=================================================================\nTotal params: 30,133\nTrainable params: 30,133\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Train\nmodel.fit(x_train, y_train,\n         batch_size=32,\n         epochs=5)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/5\n25000/25000 [==============================] - 87s 3ms/step - loss: 0.5223 - acc: 0.7375\nEpoch 2/5\n25000/25000 [==============================] - 97s 4ms/step - loss: 0.3009 - acc: 0.8816\nEpoch 3/5\n25000/25000 [==============================] - 88s 4ms/step - loss: 0.2291 - acc: 0.9169\nEpoch 4/5\n25000/25000 [==============================] - 91s 4ms/step - loss: 0.1882 - acc: 0.9363\nEpoch 5/5\n25000/25000 [==============================] - 108s 4ms/step - loss: 0.1613 - acc: 0.9464\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7ffb65b770b8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "score = model.evaluate(x_test, y_test)\nprint(f'測試資料的 loss = {score[0]}')\nprint(f'測試資正確率 = {score[1]}')",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "25000/25000 [==============================] - 18s 727us/step\n測試資料的 loss = 0.4096148190832138\n測試資正確率 = 0.85092\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 把結果存檔"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_json = model.to_json()\nopen('imdb_model_arch.json',\n     'w').write(model_json)\nmodel.save_weights('imdb_model_weights.h5')",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 做一個自己的RNN模型\n\n### 調高維度\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#維度調高\nN = 10 # 文字要壓到 N 維\nK = 10 # LSTM 有 K 個神經元",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "RNNmodel = Sequential()\nRNNmodel.add(Embedding(10000, N))\n\n#LSTM 層, 我們做 K 個 LSTM Cells。\nRNNmodel.add(LSTM(K))\n\n#單純透過 sigmoid 輸出\nRNNmodel.add(Dense(1, activation='sigmoid'))",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "RNNmodel.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\nRNNmodel.summary()",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, None, 10)          100000    \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 10)                840       \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 100,851\nTrainable params: 100,851\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Train\nRNNmodel.fit(x_train, y_train,\n         batch_size=100,\n         epochs=2)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/2\n25000/25000 [==============================] - 37s 1ms/step - loss: 0.5236 - acc: 0.7344\nEpoch 2/2\n25000/25000 [==============================] - 41s 2ms/step - loss: 0.2790 - acc: 0.8925\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7ffb501ae160>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}